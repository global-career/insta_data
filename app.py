import os
import sqlite3
import hashlib
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
import streamlit as st
from google.cloud import bigquery

# èªè¨¼ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’ã“ã“ã«æŒ‡å®šï¼ˆâ†“ã‚ãªãŸã®JSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼‰
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "/Users/toki-mac/Downloads/extreme-core-447003-m3-88f2778773a4.json"
# BigQueryã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä½œæˆ
client = bigquery.Client()

# SQLite DBæŽ¥ç¶š
conn = sqlite3.connect('user_database.db')
c = conn.cursor()


# ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒã‚·ãƒ¥é–¢æ•°
def make_hashes(password):
    return hashlib.sha256(str.encode(password)).hexdigest()

def check_hashes(password, hashed_text):
    return make_hashes(password) == hashed_text

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ç®¡ç†é–¢æ•°
def create_user_table():
    c.execute('CREATE TABLE IF NOT EXISTS userstable(username TEXT, password TEXT)')

def add_user(username, password):
    c.execute('INSERT INTO userstable(username, password) VALUES (?, ?)', (username, password))
    conn.commit()

def login_user(username, password):
    c.execute('SELECT * FROM userstable WHERE username =? AND password = ?', (username, password))
    return c.fetchall()

# ãƒ­ã‚°ã‚¤ãƒ³æ©Ÿèƒ½ãƒ¡ã‚¤ãƒ³
def main():
    st.sidebar.title("ðŸ”’ ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ­ã‚°ã‚¤ãƒ³")
    menu = ["ãƒ­ã‚°ã‚¤ãƒ³", "ã‚µã‚¤ãƒ³ã‚¢ãƒƒãƒ—"]
    choice = st.sidebar.selectbox("ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’é¸ã‚“ã§ãã ã•ã„", menu)

    if choice == "ãƒ­ã‚°ã‚¤ãƒ³":
        username = st.sidebar.text_input("ãƒ¦ãƒ¼ã‚¶ãƒ¼å")
        password = st.sidebar.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type='password')
        if st.sidebar.button("ãƒ­ã‚°ã‚¤ãƒ³"):
            create_user_table()
            result = login_user(username, make_hashes(password))
            if result:
                st.success(f"ã‚ˆã†ã“ãã€{username} ã•ã‚“ï¼")
                show_dashboard()
            else:
                st.error("ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¾ãŸã¯ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé–“é•ã£ã¦ã„ã¾ã™")

    elif choice == "ã‚µã‚¤ãƒ³ã‚¢ãƒƒãƒ—":
        st.subheader("ðŸ“ ã‚¢ã‚«ã‚¦ãƒ³ãƒˆä½œæˆ")
        new_user = st.text_input("æ–°ã—ã„ãƒ¦ãƒ¼ã‚¶ãƒ¼å")
        new_password = st.text_input("æ–°ã—ã„ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type='password')
        if st.button("ã‚¢ã‚«ã‚¦ãƒ³ãƒˆä½œæˆ"):
            create_user_table()
            add_user(new_user, make_hashes(new_password))
            st.success("ã‚¢ã‚«ã‚¦ãƒ³ãƒˆä½œæˆã«æˆåŠŸã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„ã€‚")



def show_dashboard():
    st.title("ðŸ“ˆ Global Career Community Instagramåˆ†æž")
    st.header("â‘  ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°ã®æŽ¨ç§»")

    # å¤šåˆ†ã„ã‚‰ãªã„ã€€followers_path = '/Users/toki-mac/Downloads/Streamlit data/GCC instagram data graph - InstagramData.csv'
    # å¤šåˆ†ã„ã‚‰ãªã„ã€€df_followers = pd.read_csv(followers_path)

    query_followers = """
    SELECT date, username, title, followers, posts_number, profile_image
    FROM `insta-data-460018.insta_dataset_us.followers`
    """

    df_followers = client.query(query_followers).to_dataframe()

    df_followers.columns = ["å–å¾—æ—¥æ™‚", "ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒãƒ¼ãƒ ", "åå‰", "ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°", "æŠ•ç¨¿æ•°", "ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ç”»åƒ"]
    df_followers["å–å¾—æ—¥"] = pd.to_datetime(df_followers["å–å¾—æ—¥æ™‚"]).dt.date
    df_daily = df_followers.groupby("å–å¾—æ—¥").last().reset_index()
    df_daily["å¢—æ¸›"] = df_daily["ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°"].diff()
    df_daily["ãƒ•ãƒ©ã‚°"] = df_daily["å¢—æ¸›"].apply(
        lambda x: "ãƒ‡ãƒ¼ã‚¿ãªã—" if pd.isna(x) else ("å¢—åŠ " if x > 0 else ("æ¸›å°‘" if x < 0 else "å¤‰åŒ–ãªã—"))
    )
    st.dataframe(df_daily[["å–å¾—æ—¥", "ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°", "å¢—æ¸›", "ãƒ•ãƒ©ã‚°"]])
    st.line_chart(df_daily.set_index("å–å¾—æ—¥")["ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°"])




    st.header("â‘¡ æ—¥ã”ã¨ã®ã€Œåˆè¨ˆãƒªãƒ¼ãƒæ•°ã€")
    st.write("æ—¥ã”ã¨ã®åˆè¨ˆãƒªãƒ¼ãƒæ•°ã‚’è¡¨ç¤ºä¸­ã€‚")

    # posts_path = '/Users/toki-mac/Downloads/Streamlit data/GCC insta 0414.csv'
    # df_posts = pd.read_csv(posts_path, dtype={"__ID": str}) # æŠ•ç¨¿IDãŒæ–‡å­—åˆ—ãªã®ã§ dtype ã‚’æŒ‡å®š

    query_posts = """
    SELECT date, ID, posted_date, media_type, view_count, reach, save, `like`, `comment`, `share`
    FROM `insta-data-460018.insta_dataset_us.test`
    """

    df_posts = client.query(query_posts).to_dataframe()

    df_posts.columns = ["å®Ÿè¡Œæ—¥æ™‚", "æŠ•ç¨¿ID", "æŠ•ç¨¿æ—¥æ™‚", "æŠ•ç¨¿ç¨®åˆ¥", "å†ç”Ÿå›žæ•°", "ãƒªãƒ¼ãƒ", "ä¿å­˜æ•°", "ã„ã„ã­æ•°", "ã‚³ãƒ¡ãƒ³ãƒˆæ•°", "ã‚·ã‚§ã‚¢æ•°"] 
    df_posts["å®Ÿè¡Œæ—¥æ™‚"] = df_posts["å®Ÿè¡Œæ—¥æ™‚"].str.replace(r"\d{2}:\d{2}$", "00:00", regex=True) # å®Ÿè¡Œæ—¥æ™‚ã‹ã‚‰æ™‚åˆ»éƒ¨åˆ†ã®åˆ†ã‚’00ã«ã™ã‚‹ï¼ˆä¾‹ï¼š13:24 â†’ 13:00ï¼‰
    df_posts["å®Ÿè¡Œæ—¥"] = pd.to_datetime(df_posts["å®Ÿè¡Œæ—¥æ™‚"]).dt.date # å®Ÿè¡Œæ—¥ã ã‘å–ã‚Šå‡ºã—ãŸåˆ—ã‚’è¿½åŠ ï¼ˆã‚ã¨ã§ã‚°ãƒ©ãƒ•ã«ä½¿ãˆã‚‹ï¼‰
    df_posts["ãƒªãƒ¼ãƒ"] = df_posts["ãƒªãƒ¼ãƒ"].astype(str).str.replace(",", "")
    df_posts["ãƒªãƒ¼ãƒ"] = pd.to_numeric(df_posts["ãƒªãƒ¼ãƒ"], errors='coerce')

    df_posts = df_posts.dropna(subset=['ãƒªãƒ¼ãƒ']).copy()
    df_posts.loc[:, 'ãƒªãƒ¼ãƒ'] = df_posts['ãƒªãƒ¼ãƒ'].astype(int)

    # Streamlit è¡¨ç¤ºéƒ¨åˆ†
    dairy_sum = df_posts.groupby("å®Ÿè¡Œæ—¥")["ãƒªãƒ¼ãƒ"].sum().reset_index()

    fig2, ax2 = plt.subplots(figsize=(10, 5))
    ax2.plot(dairy_sum["å®Ÿè¡Œæ—¥"], dairy_sum["ãƒªãƒ¼ãƒ"], marker='o', linestyle='-')
    ax2.set_title("æ—¥ã”ã¨ã®åˆè¨ˆãƒªãƒ¼ãƒæ•°")
    ax2.set_xlabel("æ—¥ä»˜")
    ax2.set_ylabel("åˆè¨ˆãƒªãƒ¼ãƒæ•°")
    ax2.grid(True)
    plt.xticks(rotation=45)
    plt.tight_layout()

    st.pyplot(fig2)




    st.header("â‘¢ ã‚ã‚‹æŠ•ç¨¿IDã«ã¤ã„ã¦æ—¥ã”ã¨ã®ãƒªãƒ¼ãƒæ•°ã‚’å¯è¦–åŒ–")

    target_id = '18038593490608586'
    df_target = df_posts[df_posts['æŠ•ç¨¿ID'] == target_id].copy()
    df_target['ãƒªãƒ¼ãƒ'] = pd.to_numeric(df_target['ãƒªãƒ¼ãƒ'], errors='coerce')
    df_target = df_target.dropna(subset=['ãƒªãƒ¼ãƒ'])

    daily_reach = df_target.groupby('å®Ÿè¡Œæ—¥')['ãƒªãƒ¼ãƒ'].sum().reset_index()

    fig3, ax3 = plt.subplots(figsize=(10, 5))
    ax3.plot(daily_reach['å®Ÿè¡Œæ—¥'], daily_reach['ãƒªãƒ¼ãƒ'], marker='o')
    ax3.set_title(f"æŠ•ç¨¿ID {target_id} ã®æ—¥åˆ¥ãƒªãƒ¼ãƒæ•°")
    ax3.set_xlabel("å®Ÿè¡Œæ—¥")
    ax3.set_ylabel("ãƒªãƒ¼ãƒæ•°")
    ax3.grid(True)
    ax3.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, _: f"{int(x):,}"))
    plt.xticks(rotation=45)
    plt.tight_layout()
    st.pyplot(fig3)




    st.header("â‘£ å„æŠ•ç¨¿ã”ã¨ã«æ—¥ã”ã¨ã®å·®åˆ†ã‚’é›†è¨ˆã—ã¦æ—¥ã”ã¨ã‚’KPIã‚’é›†è¨ˆ") 

    df_posts["å®Ÿè¡Œæ—¥æ™‚"] = pd.to_datetime(df_posts["å®Ÿè¡Œæ—¥æ™‚"]) # æ—¥æ™‚ã‚’DateTimeåž‹ã«å¤‰æ›
    df_posts["å®Ÿè¡Œæ—¥"] = df_posts["å®Ÿè¡Œæ—¥æ™‚"].dt.date # æ—¥ä»˜ã‚’DateTimeåž‹ã«å¤‰æ›

    kpi_cols = ['å†ç”Ÿå›žæ•°', 'ãƒªãƒ¼ãƒ', 'ä¿å­˜æ•°', 'ã„ã„ã­æ•°', 'ã‚³ãƒ¡ãƒ³ãƒˆæ•°', 'ã‚·ã‚§ã‚¢æ•°'] # å·®åˆ†ã‚’å–ã‚ŠãŸã„ KPI åˆ—ã ã‘å®šç¾©

    for col in kpi_cols:
        df_posts[col] = ( df_posts[col] #[col]ã«kpi_colsã®ã‚„ã¤ã‚‰ã‚’é †ç•ªã«ä»£å…¥
                        .astype(str)
                        .str.replace(",", "")
                        .pipe(pd.to_numeric, errors='coerce') )
        
    df_posts = df_posts.sort_values(by=["æŠ•ç¨¿ID", "å®Ÿè¡Œæ—¥æ™‚"]) # æŠ•ç¨¿ID â†’ å®Ÿè¡Œæ—¥æ™‚ã®é †ã§ä¸¦ã³æ›¿ãˆ

    for col in kpi_cols:
        df_posts[f"{col}_å¢—æ¸›"] = df_posts.groupby("æŠ•ç¨¿ID")[col].diff().fillna(0) # æŠ•ç¨¿IDã”ã¨ã«å·®åˆ†ã‚’è¨ˆç®—

    daily_per_post = (
        df_posts
        .groupby(["æŠ•ç¨¿ID", "å®Ÿè¡Œæ—¥"])[[f"{col}_å¢—æ¸›" for col in kpi_cols]]
        .sum()
        .reset_index()
    )

    st.subheader("æ—¥ã”ã¨ã®KPIåˆè¨ˆå¢—æ¸›ã‚µãƒžãƒª")
    st.dataframe(daily_per_post)

if __name__ == '__main__':
    main()


# import os
# from google.cloud import bigquery

# import base64

# import pandas as pd
# import matplotlib.pyplot as plt
# import streamlit as st
# import matplotlib.ticker as ticker

# # èªè¨¼ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’ã“ã“ã«æŒ‡å®šï¼ˆâ†“ã‚ãªãŸã®JSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼‰
# #os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "/Users/toki-mac/Downloads/extreme-core-447003-m3-88f2778773a4.json"
# # Base64ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸJSONæ–‡å­—åˆ—ã‚’Secretsã‹ã‚‰å–å¾—
# b64_json = st.secrets["GOOGLE_APPLICATION_CREDENTIALS_JSON"]

# # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦æ›¸ãå‡ºã™
# tmp_json_path = "/tmp/gcp_key.json"
# with open(tmp_json_path, "wb") as f:
#     f.write(base64.b64decode(b64_json))

# # ç’°å¢ƒå¤‰æ•°ã«ã‚»ãƒƒãƒˆï¼ˆBigQueryãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã“ã“ã‚’å‚ç…§ï¼‰
# os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = tmp_json_path

# # BigQueryã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä½œæˆ
# client = bigquery.Client()

# st.title("ðŸ“ˆ Global Career Community Instagramåˆ†æž")

# st.header("â‘  æ—¥ã”ã¨ã®ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°ã®æŽ¨ç§»")

# # å¤šåˆ†ã„ã‚‰ãªã„ã€€followers_path = '/Users/toki-mac/Downloads/Streamlit data/GCC instagram data graph - InstagramData.csv'
# # å¤šåˆ†ã„ã‚‰ãªã„ã€€df_followers = pd.read_csv(followers_path)

# query_followers = """
# SELECT date, username, title, followers, posts_number, profile_image
# FROM `insta-data-460018.insta_dataset_us.followers`
# """

# df_followers = client.query(query_followers).to_dataframe()

# df_followers.columns = ["å–å¾—æ—¥æ™‚", "ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒãƒ¼ãƒ ", "åå‰", "ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°", "æŠ•ç¨¿æ•°", "ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ç”»åƒ"]
# df_followers["å–å¾—æ—¥"] = pd.to_datetime(df_followers["å–å¾—æ—¥æ™‚"]).dt.date
# df_daily = df_followers.groupby("å–å¾—æ—¥").last().reset_index()
# df_daily["å¢—æ¸›"] = df_daily["ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°"].diff()
# df_daily["ãƒ•ãƒ©ã‚°"] = df_daily["å¢—æ¸›"].apply(
#     lambda x: "ãƒ‡ãƒ¼ã‚¿ãªã—" if pd.isna(x) else ("å¢—åŠ " if x > 0 else ("æ¸›å°‘" if x < 0 else "å¤‰åŒ–ãªã—"))
# )
# st.dataframe(df_daily[["å–å¾—æ—¥", "ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°", "å¢—æ¸›", "ãƒ•ãƒ©ã‚°"]])
# st.line_chart(df_daily.set_index("å–å¾—æ—¥")["ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°"])




# st.header("â‘¡ æ—¥ã”ã¨ã®ã€Œåˆè¨ˆãƒªãƒ¼ãƒæ•°ã€")
# st.write("æ—¥ã”ã¨ã®åˆè¨ˆãƒªãƒ¼ãƒæ•°ã‚’è¡¨ç¤ºä¸­ã€‚")

# # posts_path = '/Users/toki-mac/Downloads/Streamlit data/GCC insta 0414.csv'
# # df_posts = pd.read_csv(posts_path, dtype={"__ID": str}) # æŠ•ç¨¿IDãŒæ–‡å­—åˆ—ãªã®ã§ dtype ã‚’æŒ‡å®š

# query_posts = """
# SELECT date, ID, posted_date, media_type, view_count, reach, save, `like`, `comment`, `share`
# FROM `insta-data-460018.insta_dataset_us.test`
# """

# df_posts = client.query(query_posts).to_dataframe()

# df_posts.columns = ["å®Ÿè¡Œæ—¥æ™‚", "æŠ•ç¨¿ID", "æŠ•ç¨¿æ—¥æ™‚", "æŠ•ç¨¿ç¨®åˆ¥", "å†ç”Ÿå›žæ•°", "ãƒªãƒ¼ãƒ", "ä¿å­˜æ•°", "ã„ã„ã­æ•°", "ã‚³ãƒ¡ãƒ³ãƒˆæ•°", "ã‚·ã‚§ã‚¢æ•°"] 
# df_posts["å®Ÿè¡Œæ—¥æ™‚"] = df_posts["å®Ÿè¡Œæ—¥æ™‚"].str.replace(r"\d{2}:\d{2}$", "00:00", regex=True) # å®Ÿè¡Œæ—¥æ™‚ã‹ã‚‰æ™‚åˆ»éƒ¨åˆ†ã®åˆ†ã‚’00ã«ã™ã‚‹ï¼ˆä¾‹ï¼š13:24 â†’ 13:00ï¼‰
# df_posts["å®Ÿè¡Œæ—¥"] = pd.to_datetime(df_posts["å®Ÿè¡Œæ—¥æ™‚"]).dt.date # å®Ÿè¡Œæ—¥ã ã‘å–ã‚Šå‡ºã—ãŸåˆ—ã‚’è¿½åŠ ï¼ˆã‚ã¨ã§ã‚°ãƒ©ãƒ•ã«ä½¿ãˆã‚‹ï¼‰
# df_posts["ãƒªãƒ¼ãƒ"] = df_posts["ãƒªãƒ¼ãƒ"].astype(str).str.replace(",", "")
# df_posts["ãƒªãƒ¼ãƒ"] = pd.to_numeric(df_posts["ãƒªãƒ¼ãƒ"], errors='coerce')

# df_posts = df_posts.dropna(subset=['ãƒªãƒ¼ãƒ']).copy()
# df_posts.loc[:, 'ãƒªãƒ¼ãƒ'] = df_posts['ãƒªãƒ¼ãƒ'].astype(int)

# # Streamlit è¡¨ç¤ºéƒ¨åˆ†
# dairy_sum = df_posts.groupby("å®Ÿè¡Œæ—¥")["ãƒªãƒ¼ãƒ"].sum().reset_index()

# fig2, ax2 = plt.subplots(figsize=(10, 5))
# ax2.plot(dairy_sum["å®Ÿè¡Œæ—¥"], dairy_sum["ãƒªãƒ¼ãƒ"], marker='o', linestyle='-')
# ax2.set_title("æ—¥ã”ã¨ã®åˆè¨ˆãƒªãƒ¼ãƒæ•°")
# ax2.set_xlabel("æ—¥ä»˜")
# ax2.set_ylabel("åˆè¨ˆãƒªãƒ¼ãƒæ•°")
# ax2.grid(True)
# plt.xticks(rotation=45)
# plt.tight_layout()

# st.pyplot(fig2)




# st.header("â‘¢ ã‚ã‚‹æŠ•ç¨¿IDã«ã¤ã„ã¦æ—¥ã”ã¨ã®ãƒªãƒ¼ãƒæ•°ã‚’å¯è¦–åŒ–")

# target_id = '18038593490608586'
# df_target = df_posts[df_posts['æŠ•ç¨¿ID'] == target_id].copy()
# df_target['ãƒªãƒ¼ãƒ'] = pd.to_numeric(df_target['ãƒªãƒ¼ãƒ'], errors='coerce')
# df_target = df_target.dropna(subset=['ãƒªãƒ¼ãƒ'])

# daily_reach = df_target.groupby('å®Ÿè¡Œæ—¥')['ãƒªãƒ¼ãƒ'].sum().reset_index()

# fig3, ax3 = plt.subplots(figsize=(10, 5))
# ax3.plot(daily_reach['å®Ÿè¡Œæ—¥'], daily_reach['ãƒªãƒ¼ãƒ'], marker='o')
# ax3.set_title(f"æŠ•ç¨¿ID {target_id} ã®æ—¥åˆ¥ãƒªãƒ¼ãƒæ•°")
# ax3.set_xlabel("å®Ÿè¡Œæ—¥")
# ax3.set_ylabel("ãƒªãƒ¼ãƒæ•°")
# ax3.grid(True)
# ax3.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, _: f"{int(x):,}"))
# plt.xticks(rotation=45)
# plt.tight_layout()
# st.pyplot(fig3)




# st.header("â‘£ å„æŠ•ç¨¿ã”ã¨ã«æ—¥ã”ã¨ã®å·®åˆ†ã‚’é›†è¨ˆã—ã¦æ—¥ã”ã¨ã‚’KPIã‚’é›†è¨ˆ") 

# df_posts["å®Ÿè¡Œæ—¥æ™‚"] = pd.to_datetime(df_posts["å®Ÿè¡Œæ—¥æ™‚"]) # æ—¥æ™‚ã‚’DateTimeåž‹ã«å¤‰æ›
# df_posts["å®Ÿè¡Œæ—¥"] = df_posts["å®Ÿè¡Œæ—¥æ™‚"].dt.date # æ—¥ä»˜ã‚’DateTimeåž‹ã«å¤‰æ›

# kpi_cols = ['å†ç”Ÿå›žæ•°', 'ãƒªãƒ¼ãƒ', 'ä¿å­˜æ•°', 'ã„ã„ã­æ•°', 'ã‚³ãƒ¡ãƒ³ãƒˆæ•°', 'ã‚·ã‚§ã‚¢æ•°'] # å·®åˆ†ã‚’å–ã‚ŠãŸã„ KPI åˆ—ã ã‘å®šç¾©

# for col in kpi_cols:
#     df_posts[col] = ( df_posts[col] #[col]ã«kpi_colsã®ã‚„ã¤ã‚‰ã‚’é †ç•ªã«ä»£å…¥
#                      .astype(str)
#                      .str.replace(",", "")
#                      .pipe(pd.to_numeric, errors='coerce') )
    
# df_posts = df_posts.sort_values(by=["æŠ•ç¨¿ID", "å®Ÿè¡Œæ—¥æ™‚"]) # æŠ•ç¨¿ID â†’ å®Ÿè¡Œæ—¥æ™‚ã®é †ã§ä¸¦ã³æ›¿ãˆ

# for col in kpi_cols:
#     df_posts[f"{col}_å¢—æ¸›"] = df_posts.groupby("æŠ•ç¨¿ID")[col].diff().fillna(0) # æŠ•ç¨¿IDã”ã¨ã«å·®åˆ†ã‚’è¨ˆç®—

# daily_per_post = (
#     df_posts
#     .groupby(["æŠ•ç¨¿ID", "å®Ÿè¡Œæ—¥"])[[f"{col}_å¢—æ¸›" for col in kpi_cols]]
#     .sum()
#     .reset_index()
# )
# print("hello")
# st.subheader("æ—¥ã”ã¨ã®KPIåˆè¨ˆå¢—æ¸›ã‚µãƒžãƒª")
# st.dataframe(daily_per_post)


